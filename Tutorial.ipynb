{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pthisQvxa2sN"
   },
   "source": [
    "# Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "HYyhtoOodUcZ"
   },
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "!python split_dataset_tvt.py --train 90 --validation 10 --folder root_data/train --dest data/train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ªë l∆∞·ª£ng ·∫£nh trong th∆∞ m·ª•c train: 10367\n",
      "S·ªë l∆∞·ª£ng ·∫£nh trong th∆∞ m·ª•c val: 1154\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n t·ªõi c√°c th∆∞ m·ª•c\n",
    "train_images_path = './data/train_dataset/images/train'\n",
    "val_images_path = './data/train_dataset/images/val'\n",
    "\n",
    "# ƒê·∫øm s·ªë l∆∞·ª£ng file ·∫£nh trong m·ªôt th∆∞ m·ª•c\n",
    "def count_images(path):\n",
    "    return len([file for file in os.listdir(path) if file.endswith(('.jpg', '.png'))])\n",
    "\n",
    "# ƒê·∫øm s·ªë l∆∞·ª£ng ·∫£nh trong c√°c th∆∞ m·ª•c train v√† val\n",
    "train_images_count = count_images(train_images_path)\n",
    "val_images_count = count_images(val_images_path)\n",
    "\n",
    "print(f\"S·ªë l∆∞·ª£ng ·∫£nh trong th∆∞ m·ª•c train: {train_images_count}\")\n",
    "print(f\"S·ªë l∆∞·ª£ng ·∫£nh trong th∆∞ m·ª•c val: {val_images_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fuB3Q73ua6MZ"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_yaml = \"config_model/yolov8/yolov8l-DySample.yaml\"\n",
    "base_model = \"yolov8l.pt\"\n",
    "data_yaml = \"data/train_dataset/data.yaml\"\n",
    "name = \"yolov8l_DySample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred 491/601 items from pretrained weights\n",
      "New https://pypi.org/project/ultralytics/8.3.51 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.22 üöÄ Python-3.11.9 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 15970MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=config_model/yolov8/yolov8l-DySample.yaml, data=data/train_dataset/data.yaml, epochs=100, time=None, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=runs/train, name=yolov8l_DySample, exist_ok=False, pretrained=True, optimizer=SGD, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.95, weight_decay=0.0001, warmup_epochs=10.0, warmup_momentum=0.5, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=2.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/train/yolov8l_DySample\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 2]             \n",
      "  8                  -1  3  17836032  ultralytics.nn.modules.block.C2f             [1024, 1024, 3, True]         \n",
      "  9                  -1  1   2624512  ultralytics.nn.modules.block.SPPF            [1024, 1024, 5]               \n",
      " 10                  -1  1     32800  ultralytics.nn.extra_modules.dysample.DySample[1024]                        \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   4985856  ultralytics.nn.modules.block.C2f             [1536, 512, 3]                \n",
      " 13                  -1  1     16416  ultralytics.nn.extra_modules.dysample.DySample[512]                         \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3  18360320  ultralytics.nn.modules.block.C2f             [1536, 1024, 3]               \n",
      " 22        [15, 18, 21]  1   7060444  ultralytics.nn.modules.head.Detect           [4, [256, 512, 1024]]         \n",
      "YOLOv8l-DySample summary: 367 layers, 76,757,852 parameters, 76,757,836 gradients, 192.6 GFLOPs\n",
      "\n",
      "Transferred 601/601 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train/yolov8l_DySample', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_da\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_01_00317.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_01_00857.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_01_00961.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_02_00316.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_02_00565.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_02_00579.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_04_00014.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_04_00016.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_04_00018.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_04_00022.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_04_00110.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_04_00257.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_04_00279.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_04_00310.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_04_00328.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_04_00346.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_04_00355.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_04_00374.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_04_00491.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_04_00514.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_04_00536.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_04_00633.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_04_00709.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_04_00716.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_04_00881.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_04_00915.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_06_00803.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_10_00135.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/train/cam_10_00136.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_data\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/val/cam_02_00951.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/data/train_dataset/images/val/cam_04_00947.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.95) with parameter groups 97 weight(decay=0.0), 106 weight(decay=0.0001), 105 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/yolov8l_DySample\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      1/100      11.4G      1.825       4.36      1.297        303        640:  ^C\n",
      "      1/100      11.4G      1.825       4.36      1.297        303        640:  \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/start_train.py\", line 158, in <module>\n",
      "    main()\n",
      "  File \"/home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/start_train.py\", line 90, in main\n",
      "    model.train(\n",
      "  File \"/home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/ultralytics/engine/model.py\", line 802, in train\n",
      "    self.trainer.train()\n",
      "  File \"/home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/ultralytics/engine/trainer.py\", line 207, in train\n",
      "    self._do_train(world_size)\n",
      "  File \"/home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/ultralytics/engine/trainer.py\", line 385, in _do_train\n",
      "    self.loss, self.loss_items = self.model(batch)\n",
      "                                 ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/thang/anaconda3/envs/VehicleDetection/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/thang/anaconda3/envs/VehicleDetection/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/ultralytics/nn/tasks.py\", line 122, in forward\n",
      "    return self.loss(x, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/ultralytics/nn/tasks.py\", line 304, in loss\n",
      "    return self.criterion(preds, batch)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/ultralytics/utils/loss.py\", line 234, in __call__\n",
      "    _, target_bboxes, target_scores, fg_mask, _ = self.assigner(\n",
      "                                                  ^^^^^^^^^^^^^^\n",
      "  File \"/home/thang/anaconda3/envs/VehicleDetection/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/thang/anaconda3/envs/VehicleDetection/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/thang/anaconda3/envs/VehicleDetection/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/ultralytics/utils/tal.py\", line 72, in forward\n",
      "    mask_pos, align_metric, overlaps = self.get_pos_mask(\n",
      "                                       ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/ultralytics/utils/tal.py\", line 96, in get_pos_mask\n",
      "    mask_topk = self.select_topk_candidates(align_metric, topk_mask=mask_gt.expand(-1, -1, self.topk).bool())\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/thang/MySpace/Traffic-Vehicle-Detection-BKAI/ultralytics/utils/tal.py\", line 155, in select_topk_candidates\n",
      "    count_tensor.scatter_add_(-1, topk_idxs[:, :, k : k + 1], ones)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python start_train.py --yaml $model_yaml --model $base_model --data $data_yaml --name $name --workers 8 --batch 16 --device 0 --epochs 100 --patience 50 --hsv_h 0.015 --hsv_s 0.7 --hsv_v 0.4 --degrees 0 --translate 0.1 --scale 0.5 --mosaic 1.0 --mixup 0.0 --flipud 0 --fliplr 0.5 --shear 0.0 --perspective 0.0 --lr0 0.01 --lrf 0.01 --momentum 0.95 --weight_decay 0.0001 --warmup_epochs 10 --warmup_momentum 0.5 --warmup_bias_lr 0.1 --optimizer SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python resume_train.py --model ./runs/train/yolov8l_DySample/weights/last.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    }
   ],
   "source": [
    "!python validation.py --model runs/train/yolov8l_DySample/weights/best.pt --split val --data_dir $data_yaml --name yolov8_DySample_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on test set (public test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python validation.py --model runs/train/yolov8l_DySample/weights/best.pt --split test --data_dir $data_yaml --name yolov8_DySample_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zip predict file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "def aggregate_predictions(labels_dir, output_file):\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        for txt_file in os.listdir(labels_dir):\n",
    "            if txt_file.endswith('.txt'):\n",
    "                image_name = txt_file.replace('.txt', '.jpg')\n",
    "                with open(os.path.join(labels_dir, txt_file), 'r') as infile:\n",
    "                    for line in infile:\n",
    "                        outfile.write(f\"{image_name} {line.strip()}\\n\")\n",
    "\n",
    "def zip_file(file_path, zip_path):\n",
    "    with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "        zipf.write(file_path, os.path.basename(file_path))\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n t·ªõi th∆∞ m·ª•c ch·ª©a c√°c file nh√£n\n",
    "labels_dir = 'runs/test/yolov8_DySample_test/labels'\n",
    "\n",
    "# T√™n file ƒë·∫ßu ra\n",
    "output_file = 'predict.txt'\n",
    "# T√™n file zip ƒë·∫ßu ra\n",
    "zip_path = 'predict.zip'\n",
    "\n",
    "# T·ªïng h·ª£p c√°c file d·ª± ƒëo√°n th√†nh m·ªôt file predict.txt\n",
    "aggregate_predictions(labels_dir, output_file)\n",
    "\n",
    "# N√©n file predict.txt th√†nh predict.zip\n",
    "zip_file(output_file, zip_path)\n",
    "\n",
    "print(f\"File d·ª± ƒëo√°n ƒë√£ ƒë∆∞·ª£c t·ªïng h·ª£p v√† n√©n th√†nh c√¥ng\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_path):\n",
    "    labels = []\n",
    "    with open(label_path, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            label = {\n",
    "                'class': int(parts[0]),\n",
    "                'x_center': float(parts[1]),\n",
    "                'y_center': float(parts[2]),\n",
    "                'width': float(parts[3]),\n",
    "                'height': float(parts[4])\n",
    "            }\n",
    "            labels.append(label)\n",
    "    return labels\n",
    "\n",
    "def draw_bounding_boxes(image, labels):\n",
    "    h, w, _ = image.shape\n",
    "    for label in labels:\n",
    "        x_center = int(label['x_center'] * w)\n",
    "        y_center = int(label['y_center'] * h)\n",
    "        width = int(label['width'] * w)\n",
    "        height = int(label['height'] * h)\n",
    "        x_min = x_center - width // 2\n",
    "        y_min = y_center - height // 2\n",
    "        x_max = x_center + width // 2\n",
    "        y_max = y_center + height // 2\n",
    "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (255, 0, 0), 2)\n",
    "        cv2.putText(image, str(label['class']), (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_with_labels(image_path, label_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Unable to load image at {image_path}\")\n",
    "        return\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    labels = load_labels(label_path)\n",
    "    image_with_boxes = draw_bounding_boxes(image, labels)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image_with_boxes)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    # save image\n",
    "    #cv2.imwrite('image_with_boxes.jpg', cv2.cvtColor(image_with_boxes, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = './root_data/public_test/cam_10_00695.jpg'\n",
    "# label_path = './runs/detect/yolov11-vehicle-tuning-test3/labels/cam_10_00693.txt'\n",
    "label_path = './runs/test/yolov8l_DySample_test/labels/cam_10_00695.txt'\n",
    "\n",
    "display_image_with_labels(image_path, label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = 'src_1_frame_205_jpg.rf.f372ffd765ab8ec18f0bbef26d4537bb'\n",
    "\n",
    "image_path = f'./root_data/public_test/{image_name}.jpg'\n",
    "label_path = f'./runs/test/yolov8_DySample_test/labels/{image_name}.txt'\n",
    "\n",
    "display_image_with_labels(image_path, label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = 'src_2_frame_169-_jpg.rf.da143fd32d7174d503deaaea272c62cd'\n",
    "\n",
    "image_path = f'./root_data/public_test/{image_name}.jpg'\n",
    "label_path = f'./runs/test/yolov8_DySample_test/labels/{image_name}.txt'\n",
    "\n",
    "display_image_with_labels(image_path, label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = 'cam_08_00518_jpg.rf.9bc60d765e318913475c3f44ad296a26'\n",
    "\n",
    "image_path = f'./root_data/public_test/{image_name}.jpg'\n",
    "label_path = f'./runs/test/yolov8_DySample_test/labels/{image_name}.txt'\n",
    "\n",
    "display_image_with_labels(image_path, label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = \"src_1_frame_141_jpg.rf.b5143cd3c5d9b815a6e5380add41b59f\"\n",
    "\n",
    "image_path = f'./root_data/public_test/{image_name}.jpg'\n",
    "label_path = f'./runs/test/yolov8_DySample_test/labels/{image_name}.txt'\n",
    "\n",
    "display_image_with_labels(image_path, label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = \"src_2_frame_236-_jpg.rf.6bfe5740de02dd44f1dd677dbf53d878\"\n",
    "\n",
    "image_path = f'./root_data/public_test/{image_name}.jpg'\n",
    "label_path = f'./runs/test/yolov8_DySample_test/labels/{image_name}.txt'\n",
    "\n",
    "display_image_with_labels(image_path, label_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View result with NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def non_max_suppression(boxes, scores, iou_threshold):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, scores, score_threshold=0.01, nms_threshold=iou_threshold)\n",
    "    if len(indices) == 0:\n",
    "        return []\n",
    "    return [boxes[i] for i in indices.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_with_labels_nms(image_path, label_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    with open(label_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    boxes = []\n",
    "    scores = []\n",
    "    labels = []\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        class_id = int(parts[0])\n",
    "        x_center = float(parts[1]) * width\n",
    "        y_center = float(parts[2]) * height\n",
    "        box_width = float(parts[3]) * width\n",
    "        box_height = float(parts[4]) * height\n",
    "        confidence = float(parts[5])\n",
    "        x1 = int(x_center - box_width / 2)\n",
    "        y1 = int(y_center - box_height / 2)\n",
    "        x2 = int(x_center + box_width / 2)\n",
    "        y2 = int(y_center + box_height / 2)\n",
    "        boxes.append([x1, y1, x2, y2])\n",
    "        scores.append(confidence)\n",
    "        labels.append(class_id)\n",
    "    \n",
    "    # Apply Non-Maximum Suppression\n",
    "    nms_boxes = non_max_suppression(boxes, scores, iou_threshold=0.9)\n",
    "    \n",
    "    for box in nms_boxes:\n",
    "        x1, y1, x2, y2 = box\n",
    "        label = labels[boxes.index(box)]\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(image, f'{label}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow('Image with Labels', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = \"cam_08_00510_jpg.rf.2ca2d944e6c4c70ad93572990192f594\"\n",
    "\n",
    "image_path = './root_data/public_test/' + image_name + '.jpg'\n",
    "label_path = f'./runs/test/yolov8_DySample_test/labels/{image_name}.txt'\n",
    "\n",
    "# Display image with labels\n",
    "display_image_with_labels_nms(image_path, label_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied NMS to labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "iou_threshold = 0.9\n",
    "score_threshold = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(boxes, scores, iou_threshold):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, scores, score_threshold=score_threshold, nms_threshold=iou_threshold)\n",
    "    if len(indices) == 0:\n",
    "        return []\n",
    "    return [boxes[i] for i in indices.flatten()]\n",
    "\n",
    "def apply_nms_to_labels(src_folder, dst_folder, iou_threshold=iou_threshold):\n",
    "    if not os.path.exists(dst_folder):\n",
    "        os.makedirs(dst_folder)\n",
    "    \n",
    "    label_files = [f for f in os.listdir(src_folder) if f.endswith('.txt')]\n",
    "    file_count = 0\n",
    "    \n",
    "    for label_file in label_files:\n",
    "        src_label_path = os.path.join(src_folder, label_file)\n",
    "        dst_label_path = os.path.join(dst_folder, label_file)\n",
    "        \n",
    "        with open(src_label_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        \n",
    "        if not lines:\n",
    "            # If the file is empty, copy it directly to the destination\n",
    "            with open(dst_label_path, 'w') as file:\n",
    "                pass\n",
    "            file_count += 1\n",
    "            continue\n",
    "        \n",
    "        boxes = []\n",
    "        scores = []\n",
    "        labels = []\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            class_id = int(parts[0])\n",
    "            x_center = float(parts[1])\n",
    "            y_center = float(parts[2])\n",
    "            box_width = float(parts[3])\n",
    "            box_height = float(parts[4])\n",
    "            confidence = float(parts[5])\n",
    "            x1 = x_center - box_width / 2\n",
    "            y1 = y_center - box_height / 2\n",
    "            x2 = x_center + box_width / 2\n",
    "            y2 = y_center + box_height / 2\n",
    "            boxes.append([x1, y1, x2, y2])\n",
    "            scores.append(confidence)\n",
    "            labels.append(class_id)\n",
    "        \n",
    "        # Apply Non-Maximum Suppression\n",
    "        nms_boxes = non_max_suppression(boxes, scores, iou_threshold)\n",
    "        \n",
    "        if not nms_boxes:\n",
    "            # If no boxes remain after NMS, copy the original file to the destination\n",
    "            with open(dst_label_path, 'w') as file:\n",
    "                file.writelines(lines)\n",
    "        else:\n",
    "            with open(dst_label_path, 'w') as file:\n",
    "                for box in nms_boxes:\n",
    "                    x1, y1, x2, y2 = box\n",
    "                    label = labels[boxes.index(box)]\n",
    "                    x_center = (x1 + x2) / 2\n",
    "                    y_center = (y1 + y2) / 2\n",
    "                    box_width = x2 - x1\n",
    "                    box_height = y2 - y1\n",
    "                    confidence = scores[boxes.index(box)]\n",
    "                    file.write(f\"{label} {x_center} {y_center} {box_width} {box_height} {confidence}\\n\")\n",
    "        \n",
    "        file_count += 1\n",
    "    \n",
    "    print(f\"Applied NMS to {file_count} files in {src_folder} and saved to {dst_folder}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths\n",
    "src_folder = './runs/test/test_yolov8_DS/labels'\n",
    "dst_folder = './runs/test/test_yolov8_DS_NMS/labels'\n",
    "\n",
    "# Apply NMS to labels and save to new folder\n",
    "apply_nms_to_labels(src_folder, dst_folder)\n",
    "\n",
    "print(\"NMS has been applied and results saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "VehicleDetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
